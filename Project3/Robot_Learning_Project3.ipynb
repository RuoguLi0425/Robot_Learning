{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RuoguLi0425/Robot-Learning/blob/main/Robot_Learning_Project3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp8PVN5sJ9pd"
      },
      "source": [
        "# ***Important***\n",
        "\n",
        "**Before starting, make sure to read the [Assignment Instructions](https://courseworks2.columbia.edu/courses/172081/pages/assignment-instructions) page on Courseworks2 to learn the workflow for completing this project.**\n",
        "\n",
        "**Different from Projects 1 and 2**, apart from the link to your notebook, you are also required to submit the collected data file `data.pkl` and your chosen model checkpoint `dynamic.pth` to Coursework. You should put the link to your notebook in the \"Comment\" section of your submission."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inY7y5CRo97q"
      },
      "source": [
        "# Project Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPIiNSZ8hb8Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "339c270a-e841-472a-f7b0-9837c12cd844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mecs6616_sp23_project3'...\n",
            "remote: Enumerating objects: 27, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 27 (delta 11), reused 22 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (27/27), 23.05 KiB | 1.92 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "# DO NOT CHANGE\n",
        "\n",
        "# After running this cell, the folder 'mecs6616_sp23_project3' will show up in the file explorer on the left (click on the folder icon if it's not open)\n",
        "# It may take a few seconds to appear\n",
        "!git clone https://github.com/roamlab/mecs6616_sp23_project3.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ise8RAQhhs3X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bab187aa-1ae1-4f3d-fb1e-aa757f406219"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/mecs6616_sp23_project3/arm_dynamics_base.py' -> '/content/arm_dynamics_base.py'\n",
            "'/content/mecs6616_sp23_project3/arm_dynamics_teacher.py' -> '/content/arm_dynamics_teacher.py'\n",
            "'/content/mecs6616_sp23_project3/geometry.py' -> '/content/geometry.py'\n",
            "'/content/mecs6616_sp23_project3/imgs' -> '/content/imgs'\n",
            "'/content/mecs6616_sp23_project3/imgs/example.png' -> '/content/imgs/example.png'\n",
            "'/content/mecs6616_sp23_project3/render.py' -> '/content/render.py'\n",
            "'/content/mecs6616_sp23_project3/robot.py' -> '/content/robot.py'\n",
            "'/content/mecs6616_sp23_project3/score.py' -> '/content/score.py'\n"
          ]
        }
      ],
      "source": [
        "# DO NOT CHANGE\n",
        "\n",
        "# Copy all needed files into the working directory. This is simply to make accessing files easier\n",
        "!cp -av /content/mecs6616_sp23_project3/* /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gySFk93Uhb8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "734ca816-11b7-4c7e-aaeb-c2035879aa2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ray\n",
            "  Downloading ray-2.3.1-cp39-cp39-manylinux2014_x86_64.whl (58.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.9/dist-packages (from ray) (8.1.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from ray) (6.0)\n",
            "Collecting aiosignal\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.9/dist-packages (from ray) (22.2.0)\n",
            "Requirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.9/dist-packages (from ray) (1.53.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from ray) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from ray) (3.10.7)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.9/dist-packages (from ray) (4.3.3)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.9/dist-packages (from ray) (3.20.3)\n",
            "Collecting frozenlist\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting virtualenv>=20.0.24\n",
            "  Downloading virtualenv-20.21.0-py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.9/dist-packages (from ray) (1.22.4)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from ray) (1.0.5)\n",
            "Requirement already satisfied: platformdirs<4,>=2.4 in /usr/local/lib/python3.9/dist-packages (from virtualenv>=20.0.24->ray) (3.2.0)\n",
            "Collecting distlib<1,>=0.3.6\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 KB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema->ray) (0.19.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->ray) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->ray) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->ray) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->ray) (2022.12.7)\n",
            "Installing collected packages: distlib, virtualenv, frozenlist, aiosignal, ray\n",
            "Successfully installed aiosignal-1.3.1 distlib-0.3.6 frozenlist-1.3.3 ray-2.3.1 virtualenv-20.21.0\n"
          ]
        }
      ],
      "source": [
        "# DO NOT CHANGE\n",
        "\n",
        "# Install required packages\n",
        "!pip install ray"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1vjDH2fL9Tu"
      },
      "source": [
        "# Starter Code Explanation\n",
        "\n",
        "This project uses two 3-link arms, one called arm_teacher (blue) and the other called arm_student (red), as shown in the image below. For each test, a constant torque will be applied to the first joint of both arms for 5 seconds. arm_teacher is moving according to the provided ground truth forward dynamics and your job is to use deep learning to train the arm_student to learn the forward dynamics of the arm_teacher so that it can imitate its behavior. The forward dynamics is a function that takes in the current state of and an action applied to the arm, and then computes the new state of the arm. This project uses a time step of 0.01 second, meaning each time we advance the simulation, we compute the forward dynamics for 0.01 second. In the example image, the student arm is not updating its state and remains static but we will make it move after training is done.\n",
        "\n",
        "\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/roamlab/mecs6616_sp23_project3/blob/master/imgs/example.png?raw=true\" width=\"600\"/>\n",
        "</div>\n",
        "\n",
        "The interface for controlling the robot is defined in the `Robot` class in `robot.py` file. Each robot is initialized with a corresponding forward dynamics (the base class for forward dynamics definition is in `arm_dynamic_base.py`). The arm_teacher is initialized with the provided ground truth forward dynamics, as defined in `arm_dynamics_teacher.py`. You are welcome to look in-depth into this file to understand how the ground truth forward dynamics is computed for an arm, given its number of links, link mass, and viscous friction of the environment - this is recommended but not necessary to successfully complete this assignment. The state of each arm is defined with a (6,1)-dimensional numpy array (three joint positions in radians + three joint velocities in radians per second). An action is defined as the three toques (in Nm) applied to the three joints respectively, which is a (3,1) numpy array. **Throughout this project, we make the problem simpler by only applying a torque to the first joint, so the actions always look like `[torque,0,0]`.** Also, when scoring your model the robot will always start off in a hanging position, meaning an initial state of `[-pi/2,0,0,0,0,0]` so if the collected data from part 1 looks similar, the model will perform better. The `robot.py` file provides you with some functions to set/get the state and set the action for the arm. Make sure you understand `robot.py` well enough before getting started.\n",
        "\n",
        "`geometry.py` provides some geometry functions and `render.py` defines how the visualization is rendered. These two files are not of particular interest for completing this project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz0ALBOu6coY"
      },
      "source": [
        "# Part I. Data collection.\n",
        "\n",
        "You will first need to complete the cell below to collect a dataset for training the forward dynamics. After running the cell, it should generate a pickle file `data.pkl` that contains a data dictionary `data = {'X': X, 'Y': Y}`. The shape of `data['X']` should be (`num_samples`, 9), the first 6 elements are state and the last 3 elements are the action. The shape of `data['Y']` should be (`num_samples`, 6), which saves the next state after applying the action using the ground truth forward dynamics of arm_teacher.\n",
        "\n",
        "**After the data file is generated, `data.pkl` should appear under the 'Files' icon in the left sidebar. You can download this file by right clicking the file name. You are required to submit this file. Please do not change its name.**\n",
        "\n",
        "In the cell below, we have provided a minimal example of simulating the arm_teacher for 5 seconds. The GUI visualization is turned on and you should see the behavior of arm_teacher. The visualization can drastically slow down the simulator and you should turn it off when collecting a large amount of data.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAb3tE7h9uUd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1caa117f-ce56-4c6b-8108-23600271157d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (600000, 9) Y shape: (600000, 6)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from arm_dynamics_teacher import ArmDynamicsTeacher\n",
        "from robot import Robot\n",
        "import pickle\n",
        "import math\n",
        "from render import Renderer\n",
        "import time\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "# DO NOT CHANGE\n",
        "# Teacher arm\n",
        "dynamics_teacher = ArmDynamicsTeacher(\n",
        "    num_links=3,\n",
        "    link_mass=0.1,\n",
        "    link_length=1,\n",
        "    joint_viscous_friction=0.1,\n",
        "    dt=0.01\n",
        ")\n",
        "arm_teacher = Robot(dynamics_teacher)\n",
        "\n",
        "# ---\n",
        "\n",
        "# We run the simulator for 5 seconds with a time step of 0.01 second,\n",
        "# so there are 500 steps in total\n",
        "total_num_tests = 1200\n",
        "num_steps = 500\n",
        "\n",
        "# You code starts here. X and Y should eventually be populated with your collected data\n",
        "# Control the arm to collect a dataset for training the forward dynamics.\n",
        "X = np.zeros((total_num_tests * num_steps, arm_teacher.dynamics.get_state_dim() + arm_teacher.dynamics.get_action_dim()))\n",
        "Y = np.zeros((total_num_tests * num_steps, arm_teacher.dynamics.get_state_dim()))\n",
        "row_index = 0\n",
        "\n",
        "\n",
        "# GUI visualization, this will drastically reudce the speed of the simulator!\n",
        "gui = False\n",
        "\n",
        "# Define the initial state of the robot, such that it is vertical\n",
        "initial_state = np.zeros((arm_teacher.dynamics.get_state_dim(), 1))  # position + velocity\n",
        "initial_state[0] = -math.pi / 2.0\n",
        "\n",
        "def generate_torque_function(test_type):\n",
        "    if test_type == 1:\n",
        "        torque = random.uniform(-1.5, 1.5)\n",
        "        return lambda t: torque\n",
        "\n",
        "    elif test_type == 2:\n",
        "        max_torque = random.uniform(0.5, 1.5)\n",
        "        return lambda t: (max_torque / 5) * t\n",
        "\n",
        "    elif test_type == 3:\n",
        "        torque_1 = random.uniform(-1, 1)\n",
        "        torque_2 = random.uniform(-1, 1)\n",
        "        half_duration = 2.5\n",
        "        return lambda t: torque_1 if t < half_duration else torque_2\n",
        "\n",
        "\n",
        "# Initialize the GUI\n",
        "if gui:\n",
        "    renderer = Renderer()\n",
        "    time.sleep(1)\n",
        "\n",
        "for test_index in range(total_num_tests):\n",
        "    test_type = test_index % 3 + 1\n",
        "    torque_function = generate_torque_function(test_type)\n",
        "\n",
        "    # Set the initial state of the arm. Input to set_state() should be of shape (6, 1)\n",
        "    arm_teacher.set_state(initial_state)\n",
        "\n",
        "    for s in range(num_steps):\n",
        "        # Get the current state\n",
        "        state = arm_teacher.get_state()\n",
        "        # Define the action, applying 1Nm torque to the first joint\n",
        "        action = np.zeros((arm_teacher.dynamics.get_action_dim(), 1))\n",
        "\n",
        "        # Set the action. Input to set_action() should be of shape (3, 1)\n",
        "        arm_teacher.set_action(action)\n",
        "\n",
        "        action[0] = torque_function(s * 0.01)\n",
        "\n",
        "        # The advance function will simulate the action for 1 time step\n",
        "        arm_teacher.advance()\n",
        "\n",
        "        if gui:\n",
        "            renderer.plot([(arm_teacher, 'tab:blue')])\n",
        "        # Get the new state after advancing one time step\n",
        "        new_state = arm_teacher.get_state()\n",
        "\n",
        "        X[row_index, :] = np.hstack((state.flatten(), action.flatten()))\n",
        "        Y[row_index, :] = new_state.flatten()\n",
        "        row_index += 1\n",
        "\n",
        "X = X[:row_index, :]\n",
        "Y = Y[:row_index, :]\n",
        "\n",
        "print('X shape:', X.shape, 'Y shape:', Y.shape)\n",
        "# ---\n",
        "\n",
        "# DO NOT CHANGE\n",
        "# Save the collected data in the data.pkl file\n",
        "data = {'X': X, 'Y': Y}\n",
        "pickle.dump(data, open( \"data.pkl\", \"wb\" ) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lCviC34x8ar"
      },
      "source": [
        "# Part 2. Learning the forward dynamics.\n",
        "\n",
        "## Training\n",
        "\n",
        "After the data is collected, you will then need to complete the cell below to use the collected dataset to learn the forward dynamics.\n",
        "\n",
        "The code already creates the dataset class and loads the dataset with a random 0.8/0.2 train/test split for you. This cell should save the model that it trains. You should use a specific procedure for saving, outlined below.\n",
        "\n",
        "In machine learning, it is a very good practice to save not only the final model but also the checkpoints, such that you have a wider range of models to choose from. We provide a code snippet for you and for each epoch of your training, you should use it to save the model at that epoch.\n",
        "\n",
        "```\n",
        "model_folder_name = f'epoch_{epoch:04d}_loss_{test_loss:.8f}'\n",
        "if not os.path.exists(os.path.join(model_dir, model_folder_name)):\n",
        "    os.makedirs(os.path.join(model_dir, model_folder_name))\n",
        "torch.save(model.state_dict(), os.path.join(model_dir, model_folder_name, 'dynamics.pth'))\n",
        "```\n",
        "\n",
        "The output from running this code should be a folder as below:\n",
        "\n",
        "```\n",
        "models/\n",
        "    2023-03-08_23-57-50/\n",
        "        epoch_0001_loss_0.00032930/\n",
        "            dynamics.pth\n",
        "        epoch_0002_loss_0.00009413/\n",
        "            dynamics.pth   \n",
        "        ...  \n",
        "```\n",
        "\n",
        "You can see that every time you run this cell, a folder whose name is the time you started will be created under `models`. Checkpoints from all epochs will be saved and then the folder name for saving the checkpoint indicates the epoch number and loss on the holdout test set. Recording checkpoints this way allows you to easily pick the model with the smallest loss.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Important: choosing the best model\n",
        "\n",
        "Your code should keep track of the checkpoint with the smallest loss on the test set. You should save the path of that checkpoint to the variable `model_path`. An example value of `model_path` could be `models/2023-03-07_20-14-32/epoch_0046_loss_0.00000005/dynamics.pth`. In the evaluation code, the checkpoint from `model_path` will be loaded and evaluated.\n",
        "\n",
        "You should also download the `dynamic.pth` file to include in your submission."
      ],
      "metadata": {
        "id": "eLbHyqsYghhD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFxpaIrSzf-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf221a91-83bc-4e3d-b6b8-010eae845200"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss:  1.709597537076964e-05\n",
            "train_loss: 0.00186316, test_loss: 0.00001710, Epoch: 1\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0001_loss_0.00001710/dynamics.pth\n",
            "**********The best:1 Now:1**********\n",
            "test loss:  2.109066524553782e-05\n",
            "train_loss: 0.00002269, test_loss: 0.00002109, Epoch: 2\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0001_loss_0.00001710/dynamics.pth\n",
            "**********The best:1 Now:2**********\n",
            "test loss:  2.2567820595516728e-05\n",
            "train_loss: 0.00002331, test_loss: 0.00002257, Epoch: 3\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0001_loss_0.00001710/dynamics.pth\n",
            "**********The best:1 Now:3**********\n",
            "Epoch 00007: reducing learning rate of group 0 to 8.0000e-03.\n",
            "test loss:  3.761141211574189e-05\n",
            "train_loss: 0.00002314, test_loss: 0.00003761, Epoch: 4\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0001_loss_0.00001710/dynamics.pth\n",
            "**********The best:1 Now:4**********\n",
            "test loss:  3.307348635341138e-05\n",
            "train_loss: 0.00001229, test_loss: 0.00003307, Epoch: 5\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0001_loss_0.00001710/dynamics.pth\n",
            "**********The best:1 Now:5**********\n",
            "test loss:  2.193467316828901e-05\n",
            "Epoch 00012: reducing learning rate of group 0 to 6.4000e-03.\n",
            "train_loss: 0.00001804, test_loss: 0.00002193, Epoch: 6\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0001_loss_0.00001710/dynamics.pth\n",
            "**********The best:1 Now:6**********\n",
            "test loss:  2.261686566574402e-05\n",
            "train_loss: 0.00000900, test_loss: 0.00002262, Epoch: 7\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0001_loss_0.00001710/dynamics.pth\n",
            "**********The best:1 Now:7**********\n",
            "test loss:  1.217016294200827e-05\n",
            "train_loss: 0.00001266, test_loss: 0.00001217, Epoch: 8\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0008_loss_0.00001217/dynamics.pth\n",
            "**********The best:8 Now:8**********\n",
            "test loss:  3.880419861464665e-06\n",
            "train_loss: 0.00001340, test_loss: 0.00000388, Epoch: 9\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0009_loss_0.00000388/dynamics.pth\n",
            "**********The best:9 Now:9**********\n",
            "test loss:  4.19589318596536e-06\n",
            "train_loss: 0.00001056, test_loss: 0.00000420, Epoch: 10\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0009_loss_0.00000388/dynamics.pth\n",
            "**********The best:9 Now:10**********\n",
            "test loss:  8.27249299769998e-06\n",
            "train_loss: 0.00001138, test_loss: 0.00000827, Epoch: 11\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0009_loss_0.00000388/dynamics.pth\n",
            "**********The best:9 Now:11**********\n",
            "Epoch 00023: reducing learning rate of group 0 to 5.1200e-03.\n",
            "test loss:  6.983392180851903e-06\n",
            "train_loss: 0.00001040, test_loss: 0.00000698, Epoch: 12\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0009_loss_0.00000388/dynamics.pth\n",
            "**********The best:9 Now:12**********\n",
            "test loss:  6.9666303128694075e-06\n",
            "train_loss: 0.00000453, test_loss: 0.00000697, Epoch: 13\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0009_loss_0.00000388/dynamics.pth\n",
            "**********The best:9 Now:13**********\n",
            "test loss:  4.007017040900488e-06\n",
            "Epoch 00028: reducing learning rate of group 0 to 4.0960e-03.\n",
            "train_loss: 0.00000718, test_loss: 0.00000401, Epoch: 14\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0009_loss_0.00000388/dynamics.pth\n",
            "**********The best:9 Now:14**********\n",
            "test loss:  6.990853203584872e-06\n",
            "train_loss: 0.00000321, test_loss: 0.00000699, Epoch: 15\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0009_loss_0.00000388/dynamics.pth\n",
            "**********The best:9 Now:15**********\n",
            "test loss:  3.86379048696502e-06\n",
            "train_loss: 0.00000425, test_loss: 0.00000386, Epoch: 16\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0016_loss_0.00000386/dynamics.pth\n",
            "**********The best:16 Now:16**********\n",
            "test loss:  4.175020589514134e-06\n",
            "train_loss: 0.00000411, test_loss: 0.00000418, Epoch: 17\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0016_loss_0.00000386/dynamics.pth\n",
            "**********The best:16 Now:17**********\n",
            "test loss:  2.832818703761101e-06\n",
            "train_loss: 0.00000431, test_loss: 0.00000283, Epoch: 18\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0018_loss_0.00000283/dynamics.pth\n",
            "**********The best:18 Now:18**********\n",
            "test loss:  4.551911303944204e-06\n",
            "train_loss: 0.00000401, test_loss: 0.00000455, Epoch: 19\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0018_loss_0.00000283/dynamics.pth\n",
            "**********The best:18 Now:19**********\n",
            "test loss:  3.767341652860523e-06\n",
            "train_loss: 0.00000415, test_loss: 0.00000377, Epoch: 20\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0018_loss_0.00000283/dynamics.pth\n",
            "**********The best:18 Now:20**********\n",
            "Epoch 00041: reducing learning rate of group 0 to 3.2768e-03.\n",
            "test loss:  1.6004360948803273e-06\n",
            "train_loss: 0.00000419, test_loss: 0.00000160, Epoch: 21\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0021_loss_0.00000160/dynamics.pth\n",
            "**********The best:21 Now:21**********\n",
            "test loss:  2.873025931648954e-06\n",
            "train_loss: 0.00000167, test_loss: 0.00000287, Epoch: 22\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0021_loss_0.00000160/dynamics.pth\n",
            "**********The best:21 Now:22**********\n",
            "test loss:  5.776558574173881e-06\n",
            "train_loss: 0.00000277, test_loss: 0.00000578, Epoch: 23\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0021_loss_0.00000160/dynamics.pth\n",
            "**********The best:21 Now:23**********\n",
            "Epoch 00047: reducing learning rate of group 0 to 2.6214e-03.\n",
            "test loss:  4.934650064569723e-06\n",
            "train_loss: 0.00000274, test_loss: 0.00000493, Epoch: 24\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0021_loss_0.00000160/dynamics.pth\n",
            "**********The best:21 Now:24**********\n",
            "test loss:  2.2616189369273344e-06\n",
            "train_loss: 0.00000121, test_loss: 0.00000226, Epoch: 25\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0021_loss_0.00000160/dynamics.pth\n",
            "**********The best:21 Now:25**********\n",
            "test loss:  1.3018879871632786e-06\n",
            "train_loss: 0.00000165, test_loss: 0.00000130, Epoch: 26\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0026_loss_0.00000130/dynamics.pth\n",
            "**********The best:26 Now:26**********\n",
            "test loss:  1.1007474853386157e-06\n",
            "train_loss: 0.00000183, test_loss: 0.00000110, Epoch: 27\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0027_loss_0.00000110/dynamics.pth\n",
            "**********The best:27 Now:27**********\n",
            "test loss:  1.1158111950256473e-06\n",
            "train_loss: 0.00000166, test_loss: 0.00000112, Epoch: 28\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0027_loss_0.00000110/dynamics.pth\n",
            "**********The best:27 Now:28**********\n",
            "test loss:  1.4533688686905558e-06\n",
            "train_loss: 0.00000171, test_loss: 0.00000145, Epoch: 29\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0027_loss_0.00000110/dynamics.pth\n",
            "**********The best:27 Now:29**********\n",
            "Epoch 00059: reducing learning rate of group 0 to 2.0972e-03.\n",
            "test loss:  1.5072466529394055e-06\n",
            "train_loss: 0.00000166, test_loss: 0.00000151, Epoch: 30\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0027_loss_0.00000110/dynamics.pth\n",
            "**********The best:27 Now:30**********\n",
            "test loss:  7.691293343251952e-07\n",
            "train_loss: 0.00000094, test_loss: 0.00000077, Epoch: 31\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0031_loss_0.00000077/dynamics.pth\n",
            "**********The best:31 Now:31**********\n",
            "test loss:  8.360828331888115e-07\n",
            "train_loss: 0.00000117, test_loss: 0.00000084, Epoch: 32\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0031_loss_0.00000077/dynamics.pth\n",
            "**********The best:31 Now:32**********\n",
            "test loss:  8.823699483665829e-07\n",
            "train_loss: 0.00000115, test_loss: 0.00000088, Epoch: 33\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0031_loss_0.00000077/dynamics.pth\n",
            "**********The best:31 Now:33**********\n",
            "Epoch 00067: reducing learning rate of group 0 to 1.6777e-03.\n",
            "test loss:  1.139365621346163e-06\n",
            "train_loss: 0.00000124, test_loss: 0.00000114, Epoch: 34\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0031_loss_0.00000077/dynamics.pth\n",
            "**********The best:31 Now:34**********\n",
            "test loss:  4.4818592949506333e-07\n",
            "train_loss: 0.00000063, test_loss: 0.00000045, Epoch: 35\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0035_loss_0.00000045/dynamics.pth\n",
            "**********The best:35 Now:35**********\n",
            "test loss:  1.0480304181233655e-06\n",
            "train_loss: 0.00000088, test_loss: 0.00000105, Epoch: 36\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0035_loss_0.00000045/dynamics.pth\n",
            "**********The best:35 Now:36**********\n",
            "test loss:  9.075452654864572e-07\n",
            "train_loss: 0.00000084, test_loss: 0.00000091, Epoch: 37\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0035_loss_0.00000045/dynamics.pth\n",
            "**********The best:35 Now:37**********\n",
            "Epoch 00075: reducing learning rate of group 0 to 1.3422e-03.\n",
            "test loss:  8.903245010571936e-07\n",
            "train_loss: 0.00000080, test_loss: 0.00000089, Epoch: 38\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0035_loss_0.00000045/dynamics.pth\n",
            "**********The best:35 Now:38**********\n",
            "test loss:  3.693623651675656e-07\n",
            "train_loss: 0.00000050, test_loss: 0.00000037, Epoch: 39\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0039_loss_0.00000037/dynamics.pth\n",
            "**********The best:39 Now:39**********\n",
            "test loss:  4.834292737380489e-07\n",
            "train_loss: 0.00000062, test_loss: 0.00000048, Epoch: 40\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0039_loss_0.00000037/dynamics.pth\n",
            "**********The best:39 Now:40**********\n",
            "test loss:  6.60096788015115e-07\n",
            "train_loss: 0.00000062, test_loss: 0.00000066, Epoch: 41\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0039_loss_0.00000037/dynamics.pth\n",
            "**********The best:39 Now:41**********\n",
            "Epoch 00083: reducing learning rate of group 0 to 1.0737e-03.\n",
            "test loss:  6.08242367169017e-07\n",
            "train_loss: 0.00000058, test_loss: 0.00000061, Epoch: 42\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0039_loss_0.00000037/dynamics.pth\n",
            "**********The best:39 Now:42**********\n",
            "test loss:  3.343579653739918e-07\n",
            "train_loss: 0.00000040, test_loss: 0.00000033, Epoch: 43\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0043_loss_0.00000033/dynamics.pth\n",
            "**********The best:43 Now:43**********\n",
            "test loss:  4.3352090190277673e-07\n",
            "train_loss: 0.00000047, test_loss: 0.00000043, Epoch: 44\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0043_loss_0.00000033/dynamics.pth\n",
            "**********The best:43 Now:44**********\n",
            "test loss:  2.645440750015382e-07\n",
            "train_loss: 0.00000045, test_loss: 0.00000026, Epoch: 45\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0045_loss_0.00000026/dynamics.pth\n",
            "**********The best:45 Now:45**********\n",
            "test loss:  3.777567718780498e-07\n",
            "train_loss: 0.00000046, test_loss: 0.00000038, Epoch: 46\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0045_loss_0.00000026/dynamics.pth\n",
            "**********The best:45 Now:46**********\n",
            "test loss:  4.972383119176509e-07\n",
            "train_loss: 0.00000046, test_loss: 0.00000050, Epoch: 47\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0045_loss_0.00000026/dynamics.pth\n",
            "**********The best:45 Now:47**********\n",
            "Epoch 00095: reducing learning rate of group 0 to 8.5899e-04.\n",
            "test loss:  2.857661295152525e-07\n",
            "train_loss: 0.00000048, test_loss: 0.00000029, Epoch: 48\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0045_loss_0.00000026/dynamics.pth\n",
            "**********The best:45 Now:48**********\n",
            "test loss:  2.91108631600423e-07\n",
            "train_loss: 0.00000029, test_loss: 0.00000029, Epoch: 49\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0045_loss_0.00000026/dynamics.pth\n",
            "**********The best:45 Now:49**********\n",
            "test loss:  3.411573319548703e-07\n",
            "Epoch 00100: reducing learning rate of group 0 to 6.8719e-04.\n",
            "train_loss: 0.00000036, test_loss: 0.00000034, Epoch: 50\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0045_loss_0.00000026/dynamics.pth\n",
            "**********The best:45 Now:50**********\n",
            "test loss:  2.1052579312434243e-07\n",
            "train_loss: 0.00000026, test_loss: 0.00000021, Epoch: 51\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0051_loss_0.00000021/dynamics.pth\n",
            "**********The best:51 Now:51**********\n",
            "test loss:  2.7293804739277523e-07\n",
            "train_loss: 0.00000030, test_loss: 0.00000027, Epoch: 52\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0051_loss_0.00000021/dynamics.pth\n",
            "**********The best:51 Now:52**********\n",
            "test loss:  2.5622983693314915e-07\n",
            "train_loss: 0.00000029, test_loss: 0.00000026, Epoch: 53\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0051_loss_0.00000021/dynamics.pth\n",
            "**********The best:51 Now:53**********\n",
            "Epoch 00107: reducing learning rate of group 0 to 5.4976e-04.\n",
            "test loss:  2.959679817967261e-07\n",
            "train_loss: 0.00000030, test_loss: 0.00000030, Epoch: 54\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0051_loss_0.00000021/dynamics.pth\n",
            "**********The best:51 Now:54**********\n",
            "test loss:  2.303249717764781e-07\n",
            "train_loss: 0.00000022, test_loss: 0.00000023, Epoch: 55\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0051_loss_0.00000021/dynamics.pth\n",
            "**********The best:51 Now:55**********\n",
            "test loss:  2.1847050544939368e-07\n",
            "Epoch 00112: reducing learning rate of group 0 to 4.3980e-04.\n",
            "train_loss: 0.00000024, test_loss: 0.00000022, Epoch: 56\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0051_loss_0.00000021/dynamics.pth\n",
            "**********The best:51 Now:56**********\n",
            "test loss:  2.132077643916356e-07\n",
            "train_loss: 0.00000021, test_loss: 0.00000021, Epoch: 57\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0051_loss_0.00000021/dynamics.pth\n",
            "**********The best:51 Now:57**********\n",
            "test loss:  1.808805458007138e-07\n",
            "train_loss: 0.00000021, test_loss: 0.00000018, Epoch: 58\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0058_loss_0.00000018/dynamics.pth\n",
            "**********The best:58 Now:58**********\n",
            "test loss:  2.2371054898921255e-07\n",
            "train_loss: 0.00000022, test_loss: 0.00000022, Epoch: 59\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0058_loss_0.00000018/dynamics.pth\n",
            "**********The best:58 Now:59**********\n",
            "test loss:  1.796153623168095e-07\n",
            "train_loss: 0.00000021, test_loss: 0.00000018, Epoch: 60\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0060_loss_0.00000018/dynamics.pth\n",
            "**********The best:60 Now:60**********\n",
            "test loss:  2.109763281410437e-07\n",
            "train_loss: 0.00000021, test_loss: 0.00000021, Epoch: 61\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0060_loss_0.00000018/dynamics.pth\n",
            "**********The best:60 Now:61**********\n",
            "test loss:  2.4333450348024145e-07\n",
            "train_loss: 0.00000021, test_loss: 0.00000024, Epoch: 62\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0060_loss_0.00000018/dynamics.pth\n",
            "**********The best:60 Now:62**********\n",
            "Epoch 00125: reducing learning rate of group 0 to 3.5184e-04.\n",
            "test loss:  2.133929195125006e-07\n",
            "train_loss: 0.00000021, test_loss: 0.00000021, Epoch: 63\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0060_loss_0.00000018/dynamics.pth\n",
            "**********The best:60 Now:63**********\n",
            "test loss:  1.55663255322717e-07\n",
            "train_loss: 0.00000018, test_loss: 0.00000016, Epoch: 64\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0064_loss_0.00000016/dynamics.pth\n",
            "**********The best:64 Now:64**********\n",
            "test loss:  1.781903436063696e-07\n",
            "train_loss: 0.00000019, test_loss: 0.00000018, Epoch: 65\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0064_loss_0.00000016/dynamics.pth\n",
            "**********The best:64 Now:65**********\n",
            "test loss:  1.8281866965471256e-07\n",
            "train_loss: 0.00000019, test_loss: 0.00000018, Epoch: 66\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0064_loss_0.00000016/dynamics.pth\n",
            "**********The best:64 Now:66**********\n",
            "Epoch 00133: reducing learning rate of group 0 to 2.8147e-04.\n",
            "test loss:  1.6900008340906916e-07\n",
            "train_loss: 0.00000019, test_loss: 0.00000017, Epoch: 67\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0064_loss_0.00000016/dynamics.pth\n",
            "**********The best:64 Now:67**********\n",
            "test loss:  1.8024685202178148e-07\n",
            "train_loss: 0.00000017, test_loss: 0.00000018, Epoch: 68\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0064_loss_0.00000016/dynamics.pth\n",
            "**********The best:64 Now:68**********\n",
            "test loss:  1.6487360200064434e-07\n",
            "Epoch 00138: reducing learning rate of group 0 to 2.2518e-04.\n",
            "train_loss: 0.00000017, test_loss: 0.00000016, Epoch: 69\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0064_loss_0.00000016/dynamics.pth\n",
            "**********The best:64 Now:69**********\n",
            "test loss:  1.5807013689084216e-07\n",
            "train_loss: 0.00000016, test_loss: 0.00000016, Epoch: 70\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0064_loss_0.00000016/dynamics.pth\n",
            "**********The best:64 Now:70**********\n",
            "test loss:  1.6731635570366167e-07\n",
            "train_loss: 0.00000016, test_loss: 0.00000017, Epoch: 71\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0064_loss_0.00000016/dynamics.pth\n",
            "**********The best:64 Now:71**********\n",
            "Epoch 00143: reducing learning rate of group 0 to 1.8014e-04.\n",
            "test loss:  1.6372338447941578e-07\n",
            "train_loss: 0.00000016, test_loss: 0.00000016, Epoch: 72\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0064_loss_0.00000016/dynamics.pth\n",
            "**********The best:64 Now:72**********\n",
            "test loss:  1.5877154272795715e-07\n",
            "train_loss: 0.00000015, test_loss: 0.00000016, Epoch: 73\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0064_loss_0.00000016/dynamics.pth\n",
            "**********The best:64 Now:73**********\n",
            "test loss:  1.6782239899981733e-07\n",
            "Epoch 00148: reducing learning rate of group 0 to 1.4412e-04.\n",
            "train_loss: 0.00000015, test_loss: 0.00000017, Epoch: 74\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0064_loss_0.00000016/dynamics.pth\n",
            "**********The best:64 Now:74**********\n",
            "test loss:  1.611627431212052e-07\n",
            "train_loss: 0.00000015, test_loss: 0.00000016, Epoch: 75\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0064_loss_0.00000016/dynamics.pth\n",
            "**********The best:64 Now:75**********\n",
            "test loss:  1.5494263487051777e-07\n",
            "train_loss: 0.00000015, test_loss: 0.00000015, Epoch: 76\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0076_loss_0.00000015/dynamics.pth\n",
            "**********The best:76 Now:76**********\n",
            "test loss:  1.4991152997486286e-07\n",
            "train_loss: 0.00000015, test_loss: 0.00000015, Epoch: 77\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0077_loss_0.00000015/dynamics.pth\n",
            "**********The best:77 Now:77**********\n",
            "test loss:  1.4640105761761408e-07\n",
            "train_loss: 0.00000014, test_loss: 0.00000015, Epoch: 78\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0078_loss_0.00000015/dynamics.pth\n",
            "**********The best:78 Now:78**********\n",
            "test loss:  1.5051520391532828e-07\n",
            "train_loss: 0.00000015, test_loss: 0.00000015, Epoch: 79\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0078_loss_0.00000015/dynamics.pth\n",
            "**********The best:78 Now:79**********\n",
            "test loss:  1.3856571371799e-07\n",
            "train_loss: 0.00000015, test_loss: 0.00000014, Epoch: 80\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0080_loss_0.00000014/dynamics.pth\n",
            "**********The best:80 Now:80**********\n",
            "test loss:  1.4320086349310184e-07\n",
            "train_loss: 0.00000015, test_loss: 0.00000014, Epoch: 81\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0080_loss_0.00000014/dynamics.pth\n",
            "**********The best:80 Now:81**********\n",
            "test loss:  1.3827215870065856e-07\n",
            "train_loss: 0.00000015, test_loss: 0.00000014, Epoch: 82\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0082_loss_0.00000014/dynamics.pth\n",
            "**********The best:82 Now:82**********\n",
            "test loss:  1.5160364489711733e-07\n",
            "train_loss: 0.00000014, test_loss: 0.00000015, Epoch: 83\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0082_loss_0.00000014/dynamics.pth\n",
            "**********The best:82 Now:83**********\n",
            "test loss:  1.4857940338804573e-07\n",
            "train_loss: 0.00000014, test_loss: 0.00000015, Epoch: 84\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0082_loss_0.00000014/dynamics.pth\n",
            "**********The best:82 Now:84**********\n",
            "Epoch 00169: reducing learning rate of group 0 to 1.1529e-04.\n",
            "test loss:  1.4300559444772413e-07\n",
            "train_loss: 0.00000014, test_loss: 0.00000014, Epoch: 85\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0082_loss_0.00000014/dynamics.pth\n",
            "**********The best:82 Now:85**********\n",
            "test loss:  1.409919352823863e-07\n",
            "train_loss: 0.00000014, test_loss: 0.00000014, Epoch: 86\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0082_loss_0.00000014/dynamics.pth\n",
            "**********The best:82 Now:86**********\n",
            "test loss:  1.3637836791720776e-07\n",
            "train_loss: 0.00000014, test_loss: 0.00000014, Epoch: 87\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0087_loss_0.00000014/dynamics.pth\n",
            "**********The best:87 Now:87**********\n",
            "test loss:  1.40570284745678e-07\n",
            "train_loss: 0.00000014, test_loss: 0.00000014, Epoch: 88\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0087_loss_0.00000014/dynamics.pth\n",
            "**********The best:87 Now:88**********\n",
            "test loss:  1.4306128421163559e-07\n",
            "train_loss: 0.00000014, test_loss: 0.00000014, Epoch: 89\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0087_loss_0.00000014/dynamics.pth\n",
            "**********The best:87 Now:89**********\n",
            "Epoch 00179: reducing learning rate of group 0 to 9.2234e-05.\n",
            "test loss:  1.3543136893427268e-07\n",
            "train_loss: 0.00000014, test_loss: 0.00000014, Epoch: 90\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0090_loss_0.00000014/dynamics.pth\n",
            "**********The best:90 Now:90**********\n",
            "test loss:  1.3278056695635125e-07\n",
            "train_loss: 0.00000013, test_loss: 0.00000013, Epoch: 91\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0091_loss_0.00000013/dynamics.pth\n",
            "**********The best:91 Now:91**********\n",
            "test loss:  1.3461913702291403e-07\n",
            "train_loss: 0.00000014, test_loss: 0.00000013, Epoch: 92\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0091_loss_0.00000013/dynamics.pth\n",
            "**********The best:91 Now:92**********\n",
            "test loss:  1.4109303885234682e-07\n",
            "train_loss: 0.00000014, test_loss: 0.00000014, Epoch: 93\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0091_loss_0.00000013/dynamics.pth\n",
            "**********The best:91 Now:93**********\n",
            "Epoch 00187: reducing learning rate of group 0 to 7.3787e-05.\n",
            "test loss:  1.328721537833625e-07\n",
            "train_loss: 0.00000014, test_loss: 0.00000013, Epoch: 94\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0091_loss_0.00000013/dynamics.pth\n",
            "**********The best:91 Now:94**********\n",
            "test loss:  1.318050136589477e-07\n",
            "train_loss: 0.00000013, test_loss: 0.00000013, Epoch: 95\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0095_loss_0.00000013/dynamics.pth\n",
            "**********The best:95 Now:95**********\n",
            "test loss:  1.3316160011693037e-07\n",
            "train_loss: 0.00000013, test_loss: 0.00000013, Epoch: 96\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0095_loss_0.00000013/dynamics.pth\n",
            "**********The best:95 Now:96**********\n",
            "test loss:  1.309915432716006e-07\n",
            "train_loss: 0.00000013, test_loss: 0.00000013, Epoch: 97\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0097_loss_0.00000013/dynamics.pth\n",
            "**********The best:97 Now:97**********\n",
            "test loss:  1.3652589568498758e-07\n",
            "train_loss: 0.00000013, test_loss: 0.00000014, Epoch: 98\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0097_loss_0.00000013/dynamics.pth\n",
            "**********The best:97 Now:98**********\n",
            "test loss:  1.2964514629250818e-07\n",
            "train_loss: 0.00000013, test_loss: 0.00000013, Epoch: 99\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0099_loss_0.00000013/dynamics.pth\n",
            "**********The best:99 Now:99**********\n",
            "test loss:  1.2515308694579138e-07\n",
            "train_loss: 0.00000013, test_loss: 0.00000013, Epoch: 100\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0100_loss_0.00000013/dynamics.pth\n",
            "**********The best:100 Now:100**********\n",
            "test loss:  1.299404355966279e-07\n",
            "train_loss: 0.00000013, test_loss: 0.00000013, Epoch: 101\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0100_loss_0.00000013/dynamics.pth\n",
            "**********The best:100 Now:101**********\n",
            "test loss:  1.28669645071966e-07\n",
            "train_loss: 0.00000013, test_loss: 0.00000013, Epoch: 102\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0100_loss_0.00000013/dynamics.pth\n",
            "**********The best:100 Now:102**********\n",
            "Epoch 00205: reducing learning rate of group 0 to 5.9030e-05.\n",
            "test loss:  1.2843777007868578e-07\n",
            "train_loss: 0.00000013, test_loss: 0.00000013, Epoch: 103\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0100_loss_0.00000013/dynamics.pth\n",
            "**********The best:100 Now:103**********\n",
            "test loss:  1.3139391545162008e-07\n",
            "train_loss: 0.00000013, test_loss: 0.00000013, Epoch: 104\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0100_loss_0.00000013/dynamics.pth\n",
            "**********The best:100 Now:104**********\n",
            "test loss:  1.311730896939404e-07\n",
            "Epoch 00210: reducing learning rate of group 0 to 4.7224e-05.\n",
            "train_loss: 0.00000013, test_loss: 0.00000013, Epoch: 105\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0100_loss_0.00000013/dynamics.pth\n",
            "**********The best:100 Now:105**********\n",
            "test loss:  1.2593897225817348e-07\n",
            "train_loss: 0.00000013, test_loss: 0.00000013, Epoch: 106\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0100_loss_0.00000013/dynamics.pth\n",
            "**********The best:100 Now:106**********\n",
            "test loss:  1.2712339122108082e-07\n",
            "train_loss: 0.00000013, test_loss: 0.00000013, Epoch: 107\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0100_loss_0.00000013/dynamics.pth\n",
            "**********The best:100 Now:107**********\n",
            "Epoch 00215: reducing learning rate of group 0 to 3.7779e-05.\n",
            "test loss:  1.355803507981553e-07\n",
            "train_loss: 0.00000013, test_loss: 0.00000014, Epoch: 108\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0100_loss_0.00000013/dynamics.pth\n",
            "**********The best:100 Now:108**********\n",
            "test loss:  1.2491947657030285e-07\n",
            "train_loss: 0.00000013, test_loss: 0.00000012, Epoch: 109\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0109_loss_0.00000012/dynamics.pth\n",
            "**********The best:109 Now:109**********\n",
            "test loss:  1.2629840965653708e-07\n",
            "train_loss: 0.00000013, test_loss: 0.00000013, Epoch: 110\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0109_loss_0.00000012/dynamics.pth\n",
            "**********The best:109 Now:110**********\n",
            "test loss:  1.2917766604540285e-07\n",
            "train_loss: 0.00000013, test_loss: 0.00000013, Epoch: 111\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0109_loss_0.00000012/dynamics.pth\n",
            "**********The best:109 Now:111**********\n",
            "Epoch 00223: reducing learning rate of group 0 to 3.0223e-05.\n",
            "test loss:  1.2528298191464651e-07\n",
            "train_loss: 0.00000013, test_loss: 0.00000013, Epoch: 112\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0109_loss_0.00000012/dynamics.pth\n",
            "**********The best:109 Now:112**********\n",
            "test loss:  1.2765363891868256e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000013, Epoch: 113\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0109_loss_0.00000012/dynamics.pth\n",
            "**********The best:109 Now:113**********\n",
            "test loss:  1.2794684064824461e-07\n",
            "Epoch 00228: reducing learning rate of group 0 to 2.4179e-05.\n",
            "train_loss: 0.00000012, test_loss: 0.00000013, Epoch: 114\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0109_loss_0.00000012/dynamics.pth\n",
            "**********The best:109 Now:114**********\n",
            "test loss:  1.2323551183968108e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 115\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0115_loss_0.00000012/dynamics.pth\n",
            "**********The best:115 Now:115**********\n",
            "test loss:  1.2234817419927898e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 116\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0116_loss_0.00000012/dynamics.pth\n",
            "**********The best:116 Now:116**********\n",
            "test loss:  1.2397487956228303e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 117\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0116_loss_0.00000012/dynamics.pth\n",
            "**********The best:116 Now:117**********\n",
            "test loss:  1.2771028057301237e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000013, Epoch: 118\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0116_loss_0.00000012/dynamics.pth\n",
            "**********The best:116 Now:118**********\n",
            "Epoch 00237: reducing learning rate of group 0 to 1.9343e-05.\n",
            "test loss:  1.2378135195352986e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 119\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0116_loss_0.00000012/dynamics.pth\n",
            "**********The best:116 Now:119**********\n",
            "test loss:  1.2241404923803618e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 120\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0116_loss_0.00000012/dynamics.pth\n",
            "**********The best:116 Now:120**********\n",
            "test loss:  1.2506616657859128e-07\n",
            "Epoch 00242: reducing learning rate of group 0 to 1.5474e-05.\n",
            "train_loss: 0.00000012, test_loss: 0.00000013, Epoch: 121\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0116_loss_0.00000012/dynamics.pth\n",
            "**********The best:116 Now:121**********\n",
            "test loss:  1.2176809850809416e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 122\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0122_loss_0.00000012/dynamics.pth\n",
            "**********The best:122 Now:122**********\n",
            "test loss:  1.2132510673149948e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 123\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0123_loss_0.00000012/dynamics.pth\n",
            "**********The best:123 Now:123**********\n",
            "test loss:  1.2198501290564914e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 124\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0123_loss_0.00000012/dynamics.pth\n",
            "**********The best:123 Now:124**********\n",
            "test loss:  1.229177811090665e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 125\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0123_loss_0.00000012/dynamics.pth\n",
            "**********The best:123 Now:125**********\n",
            "Epoch 00251: reducing learning rate of group 0 to 1.2379e-05.\n",
            "test loss:  1.2299273732807592e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 126\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0123_loss_0.00000012/dynamics.pth\n",
            "**********The best:123 Now:126**********\n",
            "test loss:  1.2517030813323043e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000013, Epoch: 127\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0123_loss_0.00000012/dynamics.pth\n",
            "**********The best:123 Now:127**********\n",
            "test loss:  1.2147647699597048e-07\n",
            "Epoch 00256: reducing learning rate of group 0 to 9.9035e-06.\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 128\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0123_loss_0.00000012/dynamics.pth\n",
            "**********The best:123 Now:128**********\n",
            "test loss:  1.2186638199314832e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 129\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0123_loss_0.00000012/dynamics.pth\n",
            "**********The best:123 Now:129**********\n",
            "test loss:  1.2009987638469017e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 130\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0130_loss_0.00000012/dynamics.pth\n",
            "**********The best:130 Now:130**********\n",
            "test loss:  1.2067095583508566e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 131\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0130_loss_0.00000012/dynamics.pth\n",
            "**********The best:130 Now:131**********\n",
            "test loss:  1.222785000957553e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 132\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0130_loss_0.00000012/dynamics.pth\n",
            "**********The best:130 Now:132**********\n",
            "Epoch 00265: reducing learning rate of group 0 to 7.9228e-06.\n",
            "test loss:  1.205351723617317e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 133\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0130_loss_0.00000012/dynamics.pth\n",
            "**********The best:130 Now:133**********\n",
            "test loss:  1.2007974525829468e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 134\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0134_loss_0.00000012/dynamics.pth\n",
            "**********The best:134 Now:134**********\n",
            "test loss:  1.2076688339727564e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 135\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0134_loss_0.00000012/dynamics.pth\n",
            "**********The best:134 Now:135**********\n",
            "test loss:  1.2032720360840207e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 136\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0134_loss_0.00000012/dynamics.pth\n",
            "**********The best:134 Now:136**********\n",
            "Epoch 00273: reducing learning rate of group 0 to 6.3383e-06.\n",
            "test loss:  1.2065624813336247e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 137\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0134_loss_0.00000012/dynamics.pth\n",
            "**********The best:134 Now:137**********\n",
            "test loss:  1.2014982881206985e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 138\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0134_loss_0.00000012/dynamics.pth\n",
            "**********The best:134 Now:138**********\n",
            "test loss:  1.2004676393691702e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 139\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0139_loss_0.00000012/dynamics.pth\n",
            "**********The best:139 Now:139**********\n",
            "test loss:  1.2025021547401594e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 140\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0139_loss_0.00000012/dynamics.pth\n",
            "**********The best:139 Now:140**********\n",
            "test loss:  1.1992733292368977e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 141\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0141_loss_0.00000012/dynamics.pth\n",
            "**********The best:141 Now:141**********\n",
            "test loss:  1.2072189920312818e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 142\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0141_loss_0.00000012/dynamics.pth\n",
            "**********The best:141 Now:142**********\n",
            "test loss:  1.2015253224954374e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 143\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0141_loss_0.00000012/dynamics.pth\n",
            "**********The best:141 Now:143**********\n",
            "Epoch 00287: reducing learning rate of group 0 to 5.0706e-06.\n",
            "test loss:  1.206338790341969e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 144\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0141_loss_0.00000012/dynamics.pth\n",
            "**********The best:141 Now:144**********\n",
            "test loss:  1.2075989577198243e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 145\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0141_loss_0.00000012/dynamics.pth\n",
            "**********The best:141 Now:145**********\n",
            "test loss:  1.1995129002665788e-07\n",
            "Epoch 00292: reducing learning rate of group 0 to 4.0565e-06.\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 146\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0141_loss_0.00000012/dynamics.pth\n",
            "**********The best:141 Now:146**********\n",
            "test loss:  1.2003075010961577e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 147\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0141_loss_0.00000012/dynamics.pth\n",
            "**********The best:141 Now:147**********\n",
            "test loss:  1.200780058200716e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 148\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0141_loss_0.00000012/dynamics.pth\n",
            "**********The best:141 Now:148**********\n",
            "Epoch 00297: reducing learning rate of group 0 to 3.2452e-06.\n",
            "test loss:  1.1987179403168586e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 149\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0149_loss_0.00000012/dynamics.pth\n",
            "**********The best:149 Now:149**********\n",
            "test loss:  1.2043454592121823e-07\n",
            "train_loss: 0.00000012, test_loss: 0.00000012, Epoch: 150\n",
            "The top-performing model was saved at: models/2023-04-01_19-19-10/epoch_0149_loss_0.00000012/dynamics.pth\n",
            "**********The best:149 Now:150**********\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import argparse\n",
        "import time\n",
        "import pickle\n",
        "np.set_printoptions(suppress=True)\n",
        "import random\n",
        "\n",
        "random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "class DynamicDataset(Dataset):\n",
        "    def __init__(self, data_file):\n",
        "        data = pickle.load(open(data_file, \"rb\" ))\n",
        "        # X: (N, 9), Y: (N, 6)\n",
        "        self.X = data['X'].astype(np.float32)\n",
        "        self.Y = data['Y'].astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.Y[idx]\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, D_input = 9, D_output = 6):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(D_input, 128)\n",
        "        self.fc2 = nn.Linear(128, D_output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "def train(model, train_loader):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    for train_X, train_Y in train_loader:\n",
        "        train_X, train_Y = train_X.to(device), train_Y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(train_X)\n",
        "        loss = criterion(output, train_Y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    scheduler.step(train_loss)\n",
        "\n",
        "    return train_loss / len(train_loader)\n",
        "\n",
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    test_loss = 0\n",
        "\n",
        "    for test_X, test_Y in test_loader:\n",
        "        test_X, test_Y = test_X.to(device), test_Y.to(device)\n",
        "        outputs = model(test_X.float())\n",
        "        loss = criterion(outputs.float(), test_Y.float())\n",
        "        test_loss += loss.item()\n",
        "\n",
        "    test_loss = test_loss / len(test_loader)\n",
        "    print ('test loss: ', test_loss)\n",
        "\n",
        "    return test_loss\n",
        "\n",
        "\n",
        "# The ratio of the dataset used for testing\n",
        "split = 0.2\n",
        "\n",
        "# We are only using CPU, and GPU is not allowed.\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "dataset = DynamicDataset('data.pkl')\n",
        "dataset_size = len(dataset)\n",
        "test_size = int(np.floor(split * dataset_size))\n",
        "train_size = dataset_size - test_size\n",
        "train_set, test_set = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "batch_size = 500\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set,batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "model = Net(D_input = 9, D_output = 6).to(device)\n",
        "lr=0.01\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.8, patience=4, verbose=True, min_lr=1e-8)\n",
        "\n",
        "# The name of the directory to save all the checkpoints\n",
        "timestr = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "model_dir = os.path.join('models', timestr)\n",
        "\n",
        "# Keep track of the checkpoint with the smallest test loss and save in model_path\n",
        "\n",
        "model_path = None\n",
        "best_test_loss = float('inf')\n",
        "epochs = 150\n",
        "\n",
        "for epoch in range(1, 1 + epochs):\n",
        "\n",
        "    train_loss = train(model, train_loader)\n",
        "    test_loss = test(model, test_loader)\n",
        "    scheduler.step(test_loss)\n",
        "\n",
        "    if test_loss < best_test_loss:\n",
        "        best_test_loss = test_loss\n",
        "        best_epoch = epoch\n",
        "\n",
        "        # Create a folder to save the best model\n",
        "        model_folder_name = f'epoch_{epoch:04d}_loss_{test_loss:.8f}'\n",
        "        if not os.path.exists(os.path.join(model_dir, model_folder_name)):\n",
        "            os.makedirs(os.path.join(model_dir, model_folder_name))\n",
        "        torch.save(model.state_dict(), os.path.join(model_dir, model_folder_name, 'dynamics.pth'))\n",
        "        model_path = os.path.join(model_dir, model_folder_name, 'dynamics.pth')\n",
        "\n",
        "    print(f'train_loss: {train_loss:.8f}, test_loss: {test_loss:.8f}, Epoch: {epoch}')\n",
        "    print(f\"The top-performing model was saved at: {model_path}\")\n",
        "    print(f\"**********The best:{best_epoch} Now:{epoch}**********\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction\n",
        "\n",
        "After you are done with training, you need to complete the cell below to load the saved checkpoint (in function init_model) and then use it to predict the new state given the current state and action (in function dynamics_step). Please do not modify the arguments to those functions, even though you might not use all of them."
      ],
      "metadata": {
        "id": "18hwnds98XG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from arm_dynamics_base import ArmDynamicsBase\n",
        "import torch\n",
        "\n",
        "class ArmDynamicsStudent(ArmDynamicsBase):\n",
        "    def init_model(self, model_path, num_links, time_step, device):\n",
        "        # Initialize the model loading the saved model from provided model_path\n",
        "        try:\n",
        "            # Create an instance of the neural network model\n",
        "            self.model = Net(9, 6).to(device)\n",
        "            # Load the saved state dict for the model\n",
        "            model_state = torch.load(model_path, map_location=device)\n",
        "            # Load the state dict into the model and set it to evaluation mode\n",
        "            self.model.load_state_dict(model_state)\n",
        "            self.model.eval()\n",
        "            # Mark the model as loaded\n",
        "            self.model_loaded = True\n",
        "        except:\n",
        "            raise Exception(\"Error initializing model. Please check model_path, num_links, time_step, and device parameters.\")\n",
        "\n",
        "    def dynamics_step(self, state, action, dt):\n",
        "        # Check if the model has been loaded\n",
        "        if not self.model_loaded:\n",
        "            raise Exception(\"Model not initialized. Please call init_model() before using dynamics_step().\")\n",
        "        # Combine the current state and action into a numpy array\n",
        "        state_action = np.concatenate((state, action), axis=0)\n",
        "        # Convert the state-action numpy array to a PyTorch tensor\n",
        "        state_action_tensor = torch.from_numpy(state_action)\n",
        "        # Convert the data type to float and move the tensor to the specified device\n",
        "        state_action_tensor = state_action_tensor.float().to(device)\n",
        "        # Reshape the tensor to have a batch size of 1 and a single dimension for the data\n",
        "        state_action_tensor = state_action_tensor.view(1, -1)\n",
        "        # Use the model to predict the new state\n",
        "        with torch.no_grad():\n",
        "            new_state_tensor = self.model(state_action_tensor)\n",
        "        # Convert the new state tensor to a numpy array and reshape it\n",
        "        new_state = new_state_tensor.cpu().numpy().reshape(-1, 1)\n",
        "        # Return the new state\n",
        "        return new_state"
      ],
      "metadata": {
        "id": "EdEe4LbY8r1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLchnZGWZYeP"
      },
      "source": [
        "# Evaluation and Grading\n",
        "\n",
        "The total number of points for this project is 15. There are 3 types of tests, each is worth 5 points.\n",
        "\n",
        "**For each type, there are 50 tests.** For each test, you get a score of 1, 0.5, or 0. Your final grade for each type is the averaged score across 50 tests * 5.\n",
        "\n",
        "- *Type 1*: for each test, a constant torque randomly sampled from [-1.5Nm, 1.5Nm] is applied to the first joint of the arm for 5 seconds. If the MSE (Mean Squred Error) between the predicted arm state (arm_student) and the ground truth arm state (arm_teacher) is < 0.0005, you get score 1 for this test. If 0.0005 <= MSE < 0.008, you get score 0.5 for this test. Otherwise you get 0.\n",
        "- *Type 2*: for each test, a torque that linearly increases from 0 to a random torque in [0.5Nm, 1.5Nm] is applied to the first joint of the arm for 5 seconds. If MSE < 0.0005, you get score 1 for this test. If 0.0005 <= MSE < 0.008, you get score 0.5 for this test. Otherwise you get 0.\n",
        "- *Type 3*: for each test, one torque is applied for the first 2.5 seconds and another torque is applied for the remaining 2.5 seconds. Both torques are sampled from [-1Nm, 1Nm]. If MSE < 0.015, you get score 1 for this test. If 0.015 <= MSE < 0.05, you get score 0.5 for this test. Otherwise you get 0.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sITf5AIz3Bm1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d5380c2-6229-4938-cf87-d6f4a8e6261a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/2023-04-01_19-19-10/epoch_0149_loss_0.00000012/dynamics.pth\n"
          ]
        }
      ],
      "source": [
        "# DO NOT CHANGE\n",
        "# Set up grading\n",
        "\n",
        "# Make sure model_path is correctly set\n",
        "print(model_path)\n",
        "\n",
        "import importlib\n",
        "import score\n",
        "importlib.reload(score)\n",
        "\n",
        "# Create the teacher arm\n",
        "dynamics_teacher = ArmDynamicsTeacher(\n",
        "    num_links=3,\n",
        "    link_mass=0.1,\n",
        "    link_length=1,\n",
        "    joint_viscous_friction=0.1,\n",
        "    dt=0.01\n",
        ")\n",
        "arm_teacher = Robot(dynamics_teacher)\n",
        "\n",
        "# Create the student arm\n",
        "dynamics_student = ArmDynamicsStudent(\n",
        "    num_links=3,\n",
        "    link_mass=0.1,\n",
        "    link_length=1,\n",
        "    joint_viscous_friction=0.1,\n",
        "    dt=0.01\n",
        ")\n",
        "if model_path is not None:\n",
        "  dynamics_student.init_model(model_path, num_links=3, time_step=0.01, device=torch.device('cpu'))\n",
        "arm_student = Robot(dynamics_student)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZporTBmpmahZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86afae4d-3432-4fdf-8d0c-cd58cef7fb19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----------------------------------------\n",
            "TEST 1 (Torque = 0.8139619298002381 Nm)\n",
            "\n",
            "average mse: 2.6299573395969987e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 2 (Torque = -1.4377441519217955 Nm)\n",
            "\n",
            "average mse: 0.00012594843461343267\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 3 (Torque = 0.4009447047788264 Nm)\n",
            "\n",
            "average mse: 1.2895806532959836e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 4 (Torque = 0.7464116476158358 Nm)\n",
            "\n",
            "average mse: 2.0099051993593982e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 5 (Torque = -0.004478963092228838 Nm)\n",
            "\n",
            "average mse: 4.033383429199486e-07\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 6 (Torque = -0.825610063407457 Nm)\n",
            "\n",
            "average mse: 1.748909512883049e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 7 (Torque = -0.9058114057211281 Nm)\n",
            "\n",
            "average mse: 2.4923442215891962e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 8 (Torque = 0.7815921365968763 Nm)\n",
            "\n",
            "average mse: 2.3708136696468334e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 9 (Torque = -0.9926674903123937 Nm)\n",
            "\n",
            "average mse: 3.611228372027417e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 10 (Torque = -1.2349805574779693 Nm)\n",
            "\n",
            "average mse: 6.0516264203557484e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 11 (Torque = 0.5560794551033919 Nm)\n",
            "\n",
            "average mse: 9.906764065986809e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 12 (Torque = 1.3601800385848097 Nm)\n",
            "\n",
            "average mse: 0.0003772776658967219\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 13 (Torque = -1.4881552010162566 Nm)\n",
            "\n",
            "average mse: 0.00044220976544542974\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 14 (Torque = 0.03657679015732995 Nm)\n",
            "\n",
            "average mse: 9.792379924123365e-07\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 15 (Torque = 0.9378628849563406 Nm)\n",
            "\n",
            "average mse: 2.9350319818337996e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 16 (Torque = 0.33757820048816445 Nm)\n",
            "\n",
            "average mse: 1.704462813083925e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 17 (Torque = 0.6652659522953988 Nm)\n",
            "\n",
            "average mse: 1.2939408102623226e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 18 (Torque = -0.6243717954881005 Nm)\n",
            "\n",
            "average mse: 1.3857221499782655e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 19 (Torque = 1.2533223675388303 Nm)\n",
            "\n",
            "average mse: 0.00010860261208063875\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 20 (Torque = 0.6437273501930716 Nm)\n",
            "\n",
            "average mse: 1.1403103620030791e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 21 (Torque = 0.1276331040337837 Nm)\n",
            "\n",
            "average mse: 5.23119329504412e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 22 (Torque = -1.073489857195419 Nm)\n",
            "\n",
            "average mse: 5.340386447552114e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 23 (Torque = -0.37997771984559225 Nm)\n",
            "\n",
            "average mse: 1.6368132544478038e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 24 (Torque = 0.5224008451990358 Nm)\n",
            "\n",
            "average mse: 1.0708436197544428e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 25 (Torque = -0.17450047673101166 Nm)\n",
            "\n",
            "average mse: 4.607980123658607e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 26 (Torque = -0.19795802000011875 Nm)\n",
            "\n",
            "average mse: 4.995747633367217e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 27 (Torque = 0.3533009354079515 Nm)\n",
            "\n",
            "average mse: 1.64624119674801e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 28 (Torque = 0.039414727663172666 Nm)\n",
            "\n",
            "average mse: 1.102034340451848e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 29 (Torque = 0.4511915457944018 Nm)\n",
            "\n",
            "average mse: 1.1933394465577758e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 30 (Torque = 0.30311686021363315 Nm)\n",
            "\n",
            "average mse: 1.8850619564259235e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 31 (Torque = 0.9156695904982395 Nm)\n",
            "\n",
            "average mse: 3.69487733379731e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 32 (Torque = 0.06494145718090238 Nm)\n",
            "\n",
            "average mse: 2.5902651447484508e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 33 (Torque = 1.2259466424260048 Nm)\n",
            "\n",
            "average mse: 6.384322435613302e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 34 (Torque = -0.5422917330343642 Nm)\n",
            "\n",
            "average mse: 1.1549302694474873e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 35 (Torque = -1.2286219521872779 Nm)\n",
            "\n",
            "average mse: 6.018744795869353e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 36 (Torque = -0.5978998300913899 Nm)\n",
            "\n",
            "average mse: 1.3462937764890374e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 37 (Torque = -1.1580469144093506 Nm)\n",
            "\n",
            "average mse: 4.05140689148782e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 38 (Torque = 0.9860439789230302 Nm)\n",
            "\n",
            "average mse: 2.6664491052535888e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 39 (Torque = -1.3593110418322507 Nm)\n",
            "\n",
            "average mse: 5.1338035704820857e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 40 (Torque = 0.3788614449341776 Nm)\n",
            "\n",
            "average mse: 1.4278945075501372e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 41 (Torque = 0.1427584677577305 Nm)\n",
            "\n",
            "average mse: 4.581737857261874e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 42 (Torque = 0.9578609870102062 Nm)\n",
            "\n",
            "average mse: 2.6898759375249926e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 43 (Torque = -0.9031573809635631 Nm)\n",
            "\n",
            "average mse: 2.4960025371868853e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 44 (Torque = 1.0705509073731996 Nm)\n",
            "\n",
            "average mse: 8.554044902497806e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 45 (Torque = -0.44504208170373616 Nm)\n",
            "\n",
            "average mse: 1.2087127772192989e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 46 (Torque = 0.7639430745895717 Nm)\n",
            "\n",
            "average mse: 2.0680236047131272e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 47 (Torque = -0.6121148793609639 Nm)\n",
            "\n",
            "average mse: 1.3900106950473963e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 48 (Torque = 1.151809438683559 Nm)\n",
            "\n",
            "average mse: 0.00011245643959482327\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 49 (Torque = -0.5234650865032536 Nm)\n",
            "\n",
            "average mse: 1.1255875196215906e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 50 (Torque = -1.0049523068425545 Nm)\n",
            "\n",
            "average mse: 4.097082148888633e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "Final Score: 50/50*5 = 5.00\n",
            "----------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# DO NOT CHANGE\n",
        "\n",
        "# Test on randomly sampled torques from [-1.5, 1.5]\n",
        "score.score_random_torque(arm_teacher, arm_student, gui=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ra8NSxj5K9D3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a79aeebc-00d0-41bc-993d-2c56cb2fb90d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----------------------------------------\n",
            "TEST 1 (Torque 0 -> 1.2713206432667459 Nm)\n",
            "\n",
            "average mse: 3.3732573319500307e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 2 (Torque 0 -> 0.5207519493594015 Nm)\n",
            "\n",
            "average mse: 8.511316304641127e-07\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 3 (Torque 0 -> 1.1336482349262753 Nm)\n",
            "\n",
            "average mse: 2.959300181528942e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 4 (Torque 0 -> 1.2488038825386119 Nm)\n",
            "\n",
            "average mse: 3.4117768631136842e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 5 (Torque 0 -> 0.9985070123025904 Nm)\n",
            "\n",
            "average mse: 2.4961937663173963e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 6 (Torque 0 -> 0.7247966455308477 Nm)\n",
            "\n",
            "average mse: 1.5482193177844407e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 7 (Torque 0 -> 0.698062864759624 Nm)\n",
            "\n",
            "average mse: 1.4627123490744345e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 8 (Torque 0 -> 1.2605307121989586 Nm)\n",
            "\n",
            "average mse: 3.4121462631692902e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 9 (Torque 0 -> 0.6691108365625354 Nm)\n",
            "\n",
            "average mse: 1.368439566718026e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 10 (Torque 0 -> 0.5883398141740103 Nm)\n",
            "\n",
            "average mse: 1.0696492123929247e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 11 (Torque 0 -> 1.1853598183677971 Nm)\n",
            "\n",
            "average mse: 3.128361822011034e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 12 (Torque 0 -> 1.4533933461949364 Nm)\n",
            "\n",
            "average mse: 3.7919491616227356e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 13 (Torque 0 -> 0.5039482663279145 Nm)\n",
            "\n",
            "average mse: 8.082662283722955e-07\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 14 (Torque 0 -> 1.0121922633857765 Nm)\n",
            "\n",
            "average mse: 2.5454802724177546e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 15 (Torque 0 -> 1.3126209616521134 Nm)\n",
            "\n",
            "average mse: 3.2264967165324207e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 16 (Torque 0 -> 1.1125260668293881 Nm)\n",
            "\n",
            "average mse: 2.9479151355973506e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 17 (Torque 0 -> 1.2217553174317994 Nm)\n",
            "\n",
            "average mse: 3.3396041564283073e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 18 (Torque 0 -> 0.7918760681706332 Nm)\n",
            "\n",
            "average mse: 1.7796483046585596e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 19 (Torque 0 -> 1.4177741225129434 Nm)\n",
            "\n",
            "average mse: 4.121636541925736e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 20 (Torque 0 -> 1.2145757833976907 Nm)\n",
            "\n",
            "average mse: 3.3053816937765917e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 21 (Torque 0 -> 1.0425443680112614 Nm)\n",
            "\n",
            "average mse: 2.700461258378477e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 22 (Torque 0 -> 0.642170047601527 Nm)\n",
            "\n",
            "average mse: 1.2735199516818505e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 23 (Torque 0 -> 0.8733407600514692 Nm)\n",
            "\n",
            "average mse: 2.1182790350427082e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 24 (Torque 0 -> 1.1741336150663453 Nm)\n",
            "\n",
            "average mse: 3.0779684463357208e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 25 (Torque 0 -> 0.9418331744229961 Nm)\n",
            "\n",
            "average mse: 2.395500175371667e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 26 (Torque 0 -> 0.9340139933332937 Nm)\n",
            "\n",
            "average mse: 2.3820291993569926e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 27 (Torque 0 -> 1.1177669784693172 Nm)\n",
            "\n",
            "average mse: 2.9487278031593887e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 28 (Torque 0 -> 1.0131382425543909 Nm)\n",
            "\n",
            "average mse: 2.5483577333701885e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 29 (Torque 0 -> 1.1503971819314671 Nm)\n",
            "\n",
            "average mse: 2.99611006007113e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 30 (Torque 0 -> 1.1010389534045444 Nm)\n",
            "\n",
            "average mse: 2.939946965078062e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 31 (Torque 0 -> 1.3052231968327463 Nm)\n",
            "\n",
            "average mse: 3.239781464382571e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 32 (Torque 0 -> 1.0216471523936341 Nm)\n",
            "\n",
            "average mse: 2.586376820270334e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 33 (Torque 0 -> 1.4086488808086681 Nm)\n",
            "\n",
            "average mse: 4.345834058623009e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 34 (Torque 0 -> 0.8192360889885453 Nm)\n",
            "\n",
            "average mse: 1.8831757678599916e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 35 (Torque 0 -> 0.5904593492709074 Nm)\n",
            "\n",
            "average mse: 1.0763562272570985e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 36 (Torque 0 -> 0.8007000566362034 Nm)\n",
            "\n",
            "average mse: 1.81397726935407e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 37 (Torque 0 -> 0.6139843618635498 Nm)\n",
            "\n",
            "average mse: 1.1693087375458784e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 38 (Torque 0 -> 1.3286813263076767 Nm)\n",
            "\n",
            "average mse: 3.2333514239970293e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 39 (Torque 0 -> 0.5468963193892498 Nm)\n",
            "\n",
            "average mse: 9.234072938720921e-07\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 40 (Torque 0 -> 1.1262871483113925 Nm)\n",
            "\n",
            "average mse: 2.953638562642647e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 41 (Torque 0 -> 1.0475861559192436 Nm)\n",
            "\n",
            "average mse: 2.7301125931873325e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 42 (Torque 0 -> 1.3192869956700686 Nm)\n",
            "\n",
            "average mse: 3.223254585111528e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 43 (Torque 0 -> 0.6989475396788123 Nm)\n",
            "\n",
            "average mse: 1.4664596088955254e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 44 (Torque 0 -> 1.3568503024577332 Nm)\n",
            "\n",
            "average mse: 3.4445849869287953e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 45 (Torque 0 -> 0.8516526394320879 Nm)\n",
            "\n",
            "average mse: 2.0098027074532833e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 46 (Torque 0 -> 1.2546476915298572 Nm)\n",
            "\n",
            "average mse: 3.4116094404906447e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 47 (Torque 0 -> 0.7959617068796787 Nm)\n",
            "\n",
            "average mse: 1.7954001850104898e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 48 (Torque 0 -> 1.3839364795611862 Nm)\n",
            "\n",
            "average mse: 4.403887336965707e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 49 (Torque 0 -> 0.8255116378322488 Nm)\n",
            "\n",
            "average mse: 1.9041142698070088e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 50 (Torque 0 -> 0.6650158977191485 Nm)\n",
            "\n",
            "average mse: 1.3540824837462398e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "Final Score: 50/50*5 = 5.00\n",
            "----------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# DO NOT CHANGE\n",
        "\n",
        "# Test on torques that linearly increase from 0 to a random number from [0.5, 1.5]\n",
        "score.score_linear_torques(arm_teacher, arm_student, gui=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABtChtqBLcoE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b95e6de9-ebf6-49a2-c74a-59cf6273ae20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----------------------------------------\n",
            "TEST 1 (Torque 1 = 0.542641286533492 Nm,  Torque 2 = -0.21494151210682544 Nm)\n",
            "\n",
            "average mse: 1.4127882155176422e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 2 (Torque 1 = -0.958496101281197 Nm,  Torque 2 = -0.8130792508826994 Nm)\n",
            "\n",
            "average mse: 3.4410986905383896e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 3 (Torque 1 = 0.26729646985255084 Nm,  Torque 2 = 0.6422113156738569 Nm)\n",
            "\n",
            "average mse: 2.3150651949048502e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 4 (Torque 1 = 0.4976077650772237 Nm,  Torque 2 = -0.6976959607148723 Nm)\n",
            "\n",
            "average mse: 3.192433110969641e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 5 (Torque 1 = -0.0029859753948191514 Nm,  Torque 2 = -0.23177110261560085 Nm)\n",
            "\n",
            "average mse: 1.5533629777774825e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 6 (Torque 1 = -0.5504067089383047 Nm,  Torque 2 = 0.8885214244776023 Nm)\n",
            "\n",
            "average mse: 9.366377980186974e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 7 (Torque 1 = -0.603874270480752 Nm,  Torque 2 = 0.9752509498037445 Nm)\n",
            "\n",
            "average mse: 0.000132631869628502\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 8 (Torque 1 = 0.5210614243979175 Nm,  Torque 2 = -0.08739090581043185 Nm)\n",
            "\n",
            "average mse: 1.342629187325969e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 9 (Torque 1 = -0.6617783268749291 Nm,  Torque 2 = 0.6522456876854796 Nm)\n",
            "\n",
            "average mse: 4.395676265189553e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 10 (Torque 1 = -0.8233203716519795 Nm,  Torque 2 = -0.4972517315858813 Nm)\n",
            "\n",
            "average mse: 1.8850178706863436e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 11 (Torque 1 = 0.3707196367355945 Nm,  Torque 2 = 0.19474329646176858 Nm)\n",
            "\n",
            "average mse: 1.0473268179738971e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 12 (Torque 1 = 0.9067866923898731 Nm,  Torque 2 = 0.8056635206632548 Nm)\n",
            "\n",
            "average mse: 3.3526421247680086e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 13 (Torque 1 = -0.9921034673441711 Nm,  Torque 2 = 0.06911589760363013 Nm)\n",
            "\n",
            "average mse: 7.410474227227036e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 14 (Torque 1 = 0.024384526771553228 Nm,  Torque 2 = 0.18040272597084583 Nm)\n",
            "\n",
            "average mse: 2.6372628815212176e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 15 (Torque 1 = 0.625241923304227 Nm,  Torque 2 = -0.9214364655492253 Nm)\n",
            "\n",
            "average mse: 7.625040389401778e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 16 (Torque 1 = 0.2250521336587763 Nm,  Torque 2 = -0.28563648273092745 Nm)\n",
            "\n",
            "average mse: 1.2742793730545527e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 17 (Torque 1 = 0.4435106348635991 Nm,  Torque 2 = -0.8407738196880716 Nm)\n",
            "\n",
            "average mse: 2.570208532038751e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 18 (Torque 1 = -0.4162478636587337 Nm,  Torque 2 = -0.38908016331436346 Nm)\n",
            "\n",
            "average mse: 1.1859565959857504e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 19 (Torque 1 = 0.8355482450258869 Nm,  Torque 2 = -0.338561376035736 Nm)\n",
            "\n",
            "average mse: 4.910303235457617e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 20 (Torque 1 = 0.42915156679538113 Nm,  Torque 2 = 0.5476605924211917 Nm)\n",
            "\n",
            "average mse: 2.0417441190577972e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 21 (Torque 1 = 0.08508873602252254 Nm,  Torque 2 = -0.9200815826200455 Nm)\n",
            "\n",
            "average mse: 1.26186754669681e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 22 (Torque 1 = -0.7156599047969461 Nm,  Torque 2 = -0.14101564313672332 Nm)\n",
            "\n",
            "average mse: 1.3527974602901193e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 23 (Torque 1 = -0.2533184798970616 Nm,  Torque 2 = -0.3701462563146234 Nm)\n",
            "\n",
            "average mse: 1.1158627752405598e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 24 (Torque 1 = 0.34826723013269056 Nm,  Torque 2 = 0.27298228613508924 Nm)\n",
            "\n",
            "average mse: 1.524514248954915e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 25 (Torque 1 = -0.11633365115400784 Nm,  Torque 2 = -0.30730569983993394 Nm)\n",
            "\n",
            "average mse: 4.912234470784763e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 26 (Torque 1 = -0.13197201333341257 Nm,  Torque 2 = -0.9138052875900111 Nm)\n",
            "\n",
            "average mse: 1.0522590547520519e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 27 (Torque 1 = 0.23553395693863433 Nm,  Torque 2 = 0.759830349035832 Nm)\n",
            "\n",
            "average mse: 1.6700079294774105e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 28 (Torque 1 = 0.026276485108781777 Nm,  Torque 2 = 0.5264811742873621 Nm)\n",
            "\n",
            "average mse: 9.161038685256444e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 29 (Torque 1 = 0.30079436386293446 Nm,  Torque 2 = 0.7561932854497166 Nm)\n",
            "\n",
            "average mse: 1.9893086067569268e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 30 (Torque 1 = 0.20207790680908877 Nm,  Torque 2 = -0.16498171232146608 Nm)\n",
            "\n",
            "average mse: 1.0617569785734191e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 31 (Torque 1 = 0.6104463936654929 Nm,  Torque 2 = 0.21115512878751352 Nm)\n",
            "\n",
            "average mse: 3.345010144569479e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 32 (Torque 1 = 0.043294304787268256 Nm,  Torque 2 = 0.026933254816576824 Nm)\n",
            "\n",
            "average mse: 1.3317240674617027e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 33 (Torque 1 = 0.8172977616173365 Nm,  Torque 2 = 0.1956732959259473 Nm)\n",
            "\n",
            "average mse: 4.539775569797661e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 34 (Torque 1 = -0.36152782202290945 Nm,  Torque 2 = -0.47556867773609945 Nm)\n",
            "\n",
            "average mse: 3.1696726124973005e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 35 (Torque 1 = -0.8190813014581853 Nm,  Torque 2 = -0.3982573821185855 Nm)\n",
            "\n",
            "average mse: 1.8173946832868826e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 36 (Torque 1 = -0.3985998867275933 Nm,  Torque 2 = -0.9492004358997879 Nm)\n",
            "\n",
            "average mse: 2.9930639584142148e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 37 (Torque 1 = -0.7720312762729005 Nm,  Torque 2 = -0.3938748786979305 Nm)\n",
            "\n",
            "average mse: 1.3245091384865747e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 38 (Torque 1 = 0.6573626526153533 Nm,  Torque 2 = -0.5158482491929453 Nm)\n",
            "\n",
            "average mse: 4.521485832481058e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 39 (Torque 1 = -0.9062073612215005 Nm,  Torque 2 = 0.11515637732528838 Nm)\n",
            "\n",
            "average mse: 4.5227154746496154e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 40 (Torque 1 = 0.2525742966227851 Nm,  Torque 2 = 0.13101403977633508 Nm)\n",
            "\n",
            "average mse: 1.331538033089979e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 41 (Torque 1 = 0.09517231183848707 Nm,  Torque 2 = -0.049735505169898886 Nm)\n",
            "\n",
            "average mse: 5.597893167539011e-06\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 42 (Torque 1 = 0.6385739913401374 Nm,  Torque 2 = -0.4144040474209818 Nm)\n",
            "\n",
            "average mse: 3.497450869153891e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 43 (Torque 1 = -0.6021049206423754 Nm,  Torque 2 = -0.8714978786103511 Nm)\n",
            "\n",
            "average mse: 0.00012260015483720615\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 44 (Torque 1 = 0.7137006049154664 Nm,  Torque 2 = 0.9576382915152852 Nm)\n",
            "\n",
            "average mse: 7.076989411964402e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 45 (Torque 1 = -0.2966947211358242 Nm,  Torque 2 = -0.3205843127242727 Nm)\n",
            "\n",
            "average mse: 1.3545116005659261e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 46 (Torque 1 = 0.5092953830597144 Nm,  Torque 2 = -0.009902738235091357 Nm)\n",
            "\n",
            "average mse: 1.742386779625655e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 47 (Torque 1 = -0.4080765862406426 Nm,  Torque 2 = 0.9541614518453636 Nm)\n",
            "\n",
            "average mse: 6.289580706523725e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 48 (Torque 1 = 0.7678729591223725 Nm,  Torque 2 = -0.11845235019866696 Nm)\n",
            "\n",
            "average mse: 3.6270095728088166e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 49 (Torque 1 = -0.3489767243355024 Nm,  Torque 2 = -0.3634543890420976 Nm)\n",
            "\n",
            "average mse: 2.0063380687190956e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "TEST 50 (Torque 1 = -0.669968204561703 Nm,  Torque 2 = 0.03959397175076029 Nm)\n",
            "\n",
            "average mse: 1.4918403439310334e-05\n",
            "Score: 1/1\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "Final Score: 50/50*5 = 5.00\n",
            "----------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# DO NOT CHANGE\n",
        "\n",
        "# Test on one torque applied to the first 2.5s and another torque applied to the second 2.5s\n",
        "# Both torques are sampled from [-1, 1]\n",
        "score.score_two_torques(arm_teacher, arm_student, gui=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNJs1PcRpnSw"
      },
      "source": [
        "# Other Requirements and Hints\n",
        "\n",
        "- Training time: This project requires more training than the previous projects. But less than a hundred epochs of training (<= 25 mins) should suffice for achieving the full points. Again, the shorter your model training time is the better.\n",
        "- Dataset: Choosing the right policy to collect datasets for this project is important. You need to think about how to do it properly so that your trained model will pass the tests successfully. It is in general very hard to learn the ground truth forward dynamics completely (that works for any distribution of actions), and during testing small errors can accumulate, leading to drastic failure in the end. You might want to try overfitting on the test cases, to begin with. Make sure that your dataset is less than 100 Mb, which is pretty much sufficient for achieving full marks. Collecting datasets can be time-consuming and you could parallelize this process for some speed-up using [ray](https://www.ray.io/). Make sure your data collection takes <= 25 mins.\n",
        "- NO GPU: No GPU is required or allowed for this assignment and we will test your code without GPUs.\n",
        "- Loss Function: This is essentially a regression problem so think about what losses are suitable for regression.\n",
        "- Optimizer: While it is possible to use a simple optimizer to achieve the desired accuracy, the training time can be quite high. There exists a number of optimizers implemented in PyTorch that have much faster convergence.\n",
        "- Seeding. Please use seeding in your code to make sure your results are reproducible."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tIHsjpfTIn4h"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
